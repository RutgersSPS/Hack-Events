{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "SPS-Hack-GPU-KEY.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT7h-I_SXxTN",
        "colab_type": "text"
      },
      "source": [
        "# SPS Hack Night I - Spring 2020 \n",
        "\n",
        "## An Introduction to GPU Programming \n",
        "\n",
        "GPUs are incredibly efficient at highly parallel operations.\n",
        "\n",
        "Since Monte Carlo generation is a series of independent operations, we can make it more efficient through the use of a GPU.\n",
        "\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x6javAIZN1n",
        "colab_type": "text"
      },
      "source": [
        "# Numba\n",
        "\n",
        "Let's import numba, the package we will be using to speed up calculations via parallel processing, and check if it sees the GPU.\n",
        "\n",
        "**Note:** doing this on a laptop/desktop with a CUDA-capable Nvidia GPU is an incredibly long but rewarding setup process. I highly reccomend the use of conda environments to streamline the process.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S2RPanUXxTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numba import cuda\n",
        "\n",
        "print(cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "317HI4mLaHJy",
        "colab_type": "text"
      },
      "source": [
        "Now let's write some code to find pi via a Monte Carlo Simulation. We will generate an array of random numbers for x and y, then check if the magnitude of (`x[i]`, `y[i]`) is greater than or less than 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q15g04idXxTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import numba \n",
        "\n",
        "def calc_pi(n):\n",
        "    np.random.seed(0)\n",
        "    x = 2*np.random.ranf(n)-1\n",
        "    y = 2*np.random.ranf(n)-1\n",
        "    return 4*np.sum(x**2+y**2<1)/n\n",
        "\n",
        "points = 200000000\n",
        "\n",
        "t1 = time.time()\n",
        "pi = calc_pi(points)\n",
        "selftimed = time.time()-t1\n",
        "print(\"SELFTIMED \", selftimed)\n",
        "print(\"result: \", pi)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo8IwP_Ja30n",
        "colab_type": "text"
      },
      "source": [
        "We can quite simply parallelize this code using numba. The speedup is huge! Well, not that huge..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9es83gTXxTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numba\n",
        "\n",
        "run_parallel = numba.config.NUMBA_NUM_THREADS > 1\n",
        "\n",
        "@numba.njit(parallel=run_parallel)\n",
        "def calc_pi_parallel(n):\n",
        "    np.random.seed(0)\n",
        "    x = 2*np.random.ranf(n)-1\n",
        "    y = 2*np.random.ranf(n)-1\n",
        "    return 4*np.sum(x**2+y**2<1)/n\n",
        "\n",
        "t1 = time.time()\n",
        "pi = calc_pi_parallel(points)\n",
        "selftimed = time.time()-t1\n",
        "print(\"SELFTIMED Parallel \", selftimed)\n",
        "print(\"Parallel Result: \", pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsgAt-QAbt9L",
        "colab_type": "text"
      },
      "source": [
        "This is cool and all, but we can do better.\n",
        "\n",
        "Act II: Enter CUDA.\n",
        "\n",
        "-------\n",
        "\n",
        "## Using CUDA with Numba\n",
        "\n",
        "This code takes advantage of the GPU for huuuuggggeeeee results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd9zK9T7XxTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
        "\n",
        "points = 200000000000\n",
        "\n",
        "@cuda.jit\n",
        "def compute_pi(rng_states, iterations, out):\n",
        "    thread_id = cuda.grid(1)\n",
        "    inside = 0\n",
        "    for i in range(iterations):\n",
        "        x = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
        "        y = xoroshiro128p_uniform_float32(rng_states, thread_id)\n",
        "        if x**2 + y**2 <= 1.0:\n",
        "            inside += 1\n",
        "\n",
        "    out[thread_id] = 4.0 * inside / iterations\n",
        "\n",
        "threads_per_block = 64\n",
        "blocks = 24\n",
        "iterations = int(math.ceil(points / threads_per_block / blocks))\n",
        "\n",
        "t1 = time.time()\n",
        "rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=0)\n",
        "out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n",
        "compute_pi[blocks, threads_per_block](rng_states, iterations, out)\n",
        "pi = out.mean()\n",
        "selftimed = time.time()-t1\n",
        "\n",
        "print(\"SELFTIMED GPU \", selftimed)\n",
        "print(\"GPU Result: \", pi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeDOLuM1dccd",
        "colab_type": "text"
      },
      "source": [
        "Look at this awesome result! We just used a GPU to significantly speed up the caclulation of pi. What else can we do?\n",
        "\n",
        "------\n",
        "\n",
        "\n",
        "## The Monty Hall Problem\n",
        "\n",
        "Suppose you are on a game show with three doors. Behind two of the doors are goats. Behind the third is a shiny new car. You select one of the doors. The host opens a different door revealing that it contains a goat, and asks you if you would like to switch your pick. Should you?\n",
        "\n",
        "Let's use a Monte Carlo simulation to find out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX8Tvg3UcLmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import numba \n",
        "from numba import cuda\n",
        "from numba.cuda.random import create_xoroshiro128p_states, xoroshiro128p_uniform_float32\n",
        "import math\n",
        "\n",
        "trials = 2**24\n",
        "switch_guess = True\n",
        "\n",
        "@cuda.jit\n",
        "def sim(rng_states, iterations, out):\n",
        "    thread_id = cuda.grid(1)\n",
        "    \n",
        "    correct = 0\n",
        "    for i in range(iterations):\n",
        "        correct_answer = int(math.floor(3*xoroshiro128p_uniform_float32(rng_states, thread_id)))\n",
        "        guess = int(math.floor(3*xoroshiro128p_uniform_float32(rng_states, thread_id)))\n",
        "\n",
        "        open_door = 0\n",
        "        while True:\n",
        "            open_door = int(math.floor(3*xoroshiro128p_uniform_float32(rng_states, thread_id)))\n",
        "            if open_door != guess and open_door != correct_answer:\n",
        "                break\n",
        "        \n",
        "        if switch_guess:\n",
        "            for a in range(3):\n",
        "                if a!=guess and a!=open_door:\n",
        "                    final_guess = a\n",
        "                    break\n",
        "        else:\n",
        "            final_guess = guess\n",
        "\n",
        "        if correct_answer == final_guess:\n",
        "            correct += 1\n",
        "\n",
        "    out[thread_id] = correct / iterations\n",
        "\n",
        "\n",
        "threads_per_block = 64\n",
        "blocks = 24\n",
        "iterations = int(math.ceil(trials / threads_per_block / blocks))\n",
        "\n",
        "t1 = time.time()\n",
        "rng_states = create_xoroshiro128p_states(threads_per_block * blocks, seed=0)\n",
        "out = np.zeros(threads_per_block * blocks, dtype=np.float32)\n",
        "sim[blocks, threads_per_block](rng_states, iterations, out)\n",
        "percent_correct = out.mean()\n",
        "selftimed = time.time()-t1\n",
        "\n",
        "print(\"SELFTIMED GPU \", selftimed)\n",
        "print(\"GPU Result: \", percent_correct)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}